{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORKING WITH LANGCHAIN\n",
    "This workbook demonstrates usage of `Langchain` - framework that supports building applications with AI tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import datetime as dt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import quote_plus\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents.structured_output import ToolStrategy, ProviderStrategy\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.env path\n",
    "env_path = Path(__file__).resolve().parent.parent.parent / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# fetch API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# create agent using Sonar-pro model and configure other model related params\n",
    "model = ChatOpenAI(\n",
    "    model='gpt-5.2',\n",
    "    api_key=openai_api_key,\n",
    "    temperature=0.3, # higher number indicates more randomness in the model's output\n",
    "    max_tokens=500, #defines the no of words in the model's response\n",
    "    timeout=30 # max time in sec to wait for model's response\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIKI SEARCH USING TOOL\n",
    "Here we create an agent that searches wikipedia for a particular query say name of a famous personality to fetch information as per user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "import wikipedia\n",
    "\n",
    "@tool\n",
    "def get_wikipedia_information(query: str):\n",
    "    '''\n",
    "    Function that fetches information from wikipedia about a well known personality.\n",
    "    params: query: Name of a person.\n",
    "    '''\n",
    "    result = \"\"\n",
    "\n",
    "    try:\n",
    "        page = wikipedia.page(title=query,auto_suggest=True)\n",
    "        result = wikipedia.summary(page.title,sentences=3)\n",
    "        return result\n",
    "    except wikipedia.DisambiguationError as e:\n",
    "        return f\"Failed to load page due to {e}. Please be more specific.\"\n",
    "    except wikipedia.PageError as e:\n",
    "        return f\"Failed to load page due to {e}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def math_tool(expression: str):\n",
    "    '''\n",
    "    Function that computes age basis year\n",
    "    params: expression -> birth year\n",
    "    '''\n",
    "    return str(eval(expression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def compute_age_diff_basis_dates(expression: str):\n",
    "    '''\n",
    "    Function that computes age in years now.\n",
    "    params: expression: birth date\n",
    "    '''\n",
    "\n",
    "    birth_date = dt.datetime.strptime(expression, \"%Y-%m-%d\")\n",
    "    today = dt.date.today()\n",
    "\n",
    "    result = (today.year-birth_date.year)-((today.month,today.day)<(birth_date.month,birth_date.day))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING STRUCTURED OUTPUT\n",
    "In order to get response from the **LLM** in a format desired we use **Pydantic** validations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class AgeInfo(BaseModel):\n",
    "    '''\n",
    "    Age information for a person.\n",
    "    '''\n",
    "    age: str = Field(description=\"Age information in years as of the current date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agent = model + tool\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_wikipedia_information,math_tool,compute_age_diff_basis_dates],\n",
    "    response_format=AgeInfo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age='Elon Musk was born on June 28, 1971. As of today (2026-02-01), he is 54 years old.'\n"
     ]
    }
   ],
   "source": [
    "# run agent with the user query\n",
    "response = agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":'When was elon musk born? what is his age  as of today?'}]})\n",
    "print(response['structured_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD A SEMANTIC SEARCH ENGINE WITH LANGCHAIN\n",
    "The below section demonstrates usage of `Langchain` to setup a search engine over a PDF document which will help us to do the following, \n",
    "1. Extract passages in the PDF similar to input query. \n",
    "\n",
    "We build the architecture across 2 fronts namely, \n",
    "1. Data ingestion. \n",
    "2. Question/Query ansering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/soumyadipsikdar/Desktop/LLMs'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PyPDFLoader` loads one **document** object per PDF page. Since **document** object comes with *page_content* & *metadata** properties this allows us to pull content & metadata which usually consists of the document source for each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/nke-10k-2023.pdf'\n",
    "\n",
    "# setup loader to load pdf\n",
    "pdf_loader = PyPDFLoader(file_path=file_path)\n",
    "docs = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Contents\n",
      "UNITED STATES\n",
      "SECURITIES AND EXCHANGE COMMISSION\n",
      "Washington, D.C. 20549\n",
      "FORM 10-K\n",
      "(Mark One)\n",
      "☑ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(D) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "FO\n",
      "\n",
      "{'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'moddate': '2023-07-20T16:22:08-04:00', 'source': 'data/nke-10k-2023.pdf', 'total_pages': 107, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "# display content and metadata of first page\n",
    "print(f\"{docs[0].page_content[:200]}\\n\")\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of pages in the document is: 107\n"
     ]
    }
   ],
   "source": [
    "# display number of pages in the document\n",
    "print(f'No of pages in the document is: {len(docs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEXT-SPLITTERS\n",
    "`Text-splitter` splits a document into chunks of a particular size. By default `RecursiveCharacterTextSplitter` is used which uses *['\\n\\n','\\n',' ','']* to split texts while balancing context and chunk size i.e. it tries to split at paragraphs and then at sentences and then at words before finally splitting at each character. \n",
    "\n",
    "Using `text-splitter` ensures individual chunk is retrievable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of chunks/split documents post text splitting is: 516\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200,add_start_index=True)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"No of chunks/split documents post text splitting is: {len(all_splits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Table of Contents\n",
      "UNITED STATES\n",
      "SECURITIES AND EXCHANGE COMMISSION\n",
      "Washington, D.C. 20549\n",
      "FORM 10-K\n",
      "(Mark One)\n",
      "☑ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(D) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "FOR THE FISCAL YEAR ENDED MAY 31, 2023\n",
      "OR\n",
      "☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(D) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "FOR THE TRANSITION PERIOD FROM                         TO                         .\n",
      "Commission File No. 1-10635\n",
      "NIKE, Inc.\n",
      "(Exact name of Registrant as specified in its charter)\n",
      "Oregon 93-0584541\n",
      "(State or other jurisdiction of incorporation) (IRS Employer Identification No.)\n",
      "One Bowerman Drive, Beaverton, Oregon 97005-6453\n",
      "(Address of principal executive offices and zip code)\n",
      "(503) 671-6453\n",
      "(Registrant's telephone number, including area code)\n",
      "SECURITIES REGISTERED PURSUANT TO SECTION 12(B) OF THE ACT:\n",
      "Class B Common Stock NKE New York Stock Exchange\n",
      "(Title of each class) (Trading symbol) (Name of each exchange on which registered)' metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'moddate': '2023-07-20T16:22:08-04:00', 'source': 'data/nke-10k-2023.pdf', 'total_pages': 107, 'page': 0, 'page_label': '1', 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "print(all_splits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EMBEDDINGS\n",
    "Next we convert text in each chunk into fixed size vectors using `embedding`. This helps to match embedded query semantically to the right text stored in vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated fixed size vectors are of length: 3072\n"
     ]
    }
   ],
   "source": [
    "# setup embedding model from OpenAI\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\",api_key=openai_api_key)\n",
    "\n",
    "# vectorize the first 2 chunks/split documents\n",
    "vector_1 = embedding.embed_query(all_splits[0].page_content)\n",
    "vector_2 = embedding.embed_query(all_splits[1].page_content)\n",
    "\n",
    "assert len(vector_1) == len(vector_2)\n",
    "print(f\"Generated fixed size vectors are of length: {len(vector_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.011540832929313183,\n",
       " -0.018770398572087288,\n",
       " 0.00016181038517970592,\n",
       " 0.005937446374446154,\n",
       " 0.02033354714512825,\n",
       " -0.040011581033468246,\n",
       " -0.0075005958788096905,\n",
       " 0.04122176021337509,\n",
       " -0.008786411955952644,\n",
       " 0.060004767030477524]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display vector\n",
    "vector_1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VECTOR DATABASE/ VECTOR STORE\n",
    "An efficient database that stores texts/document in the form of numerical fixed-size vectors. Often setup with an `embedding` any text or document added to it are stored in the form of vector. \n",
    "\n",
    "Here we use a lightweight `InMemoryVectorStore` object. \n",
    "\n",
    "The advantage of vector store is the following, \n",
    "1. Stores texts that are similar in semantic meaning together. \n",
    "2. This makes indexing documents/chunks easier without having to go through all paragraphs one by one and by using similarity metrics such as *cosine similarity*, *Euclidian distance* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# setup InMemoryvectorstore object\n",
    "vector_store = InMemoryVectorStore(embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index documents i.e. add documents into the vector database\n",
    "ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUERING\n",
    "Now that the `vector database` has been added with chunks in the form of numerical vectors we can query it. \n",
    "\n",
    "`Quering` usually consists of the following steps, \n",
    "1. Each user query gets converted to a numerical vector of the same size as are the vectors in the database. \n",
    "2. Each query then is matched to the vectors using metrics such as *cosine similarity* etc. \n",
    "3. For each query the chunk with the most match is retrived by the system and answer is then drawn from it. \n",
    "\n",
    "For *similarity search* one can retrieve results with/without similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7455320815844053\n",
      "\n",
      "page_content='operations. We also lease an office complex in Shanghai, China, our headquarters for our Greater China geography, occupied by employees focused on implementing our\n",
      "wholesale, NIKE Direct and merchandising strategies in the region, among other functions.\n",
      "In the United States, NIKE has eight significant distribution centers. Five are located in or near Memphis, Tennessee, two of which are owned and three of which are\n",
      "leased. Two other distribution centers, one located in Indianapolis, Indiana and one located in Dayton, Tennessee, are leased and operated by third-party logistics\n",
      "providers. One distribution center for Converse is located in Ontario, California, which is leased. NIKE has a number of distribution facilities outside the United States,\n",
      "some of which are leased and operated by third-party logistics providers. The most significant distribution facilities outside the United States are located in Laakdal,' metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'moddate': '2023-07-20T16:22:08-04:00', 'source': 'data/nke-10k-2023.pdf', 'total_pages': 107, 'page': 26, 'page_label': '27', 'start_index': 804}\n"
     ]
    }
   ],
   "source": [
    "# return documents based on similarity to a string query\n",
    "results = vector_store.similarity_search_with_score(\"How many distribution centers does Nike have in the US?\")\n",
    "doc, score = results[0]\n",
    "print(f\"Score: {score}\\n\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7222294797453574\n",
      "\n",
      "page_content='Table of Contents\n",
      "GROSS MARGIN\n",
      "FISCAL 2023 COMPARED TO FISCAL 2022\n",
      "For fiscal 2023, our consolidated gross profit increased 4% to $22,292 million compared to $21,479 million for fiscal 2022. Gross margin decreased 250 basis points to\n",
      "43.5% for fiscal 2023 compared to 46.0% for fiscal 2022 due to the following:\n",
      "*Wholesale equivalent\n",
      "The decrease in gross margin for fiscal 2023 was primarily due to:\n",
      "• Higher NIKE Brand product costs, on a wholesale equivalent basis, primarily due to higher input costs and elevated inbound freight and logistics costs as well as\n",
      "product mix;\n",
      "• Lower margin in our NIKE Direct business, driven by higher promotional activity to liquidate inventory in the current period compared to lower promotional activity in\n",
      "the prior period resulting from lower available inventory supply;\n",
      "• Unfavorable changes in net foreign currency exchange rates, including hedges; and\n",
      "• Lower off-price margin, on a wholesale equivalent basis.\n",
      "This was partially offset by:' metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'moddate': '2023-07-20T16:22:08-04:00', 'source': 'data/nke-10k-2023.pdf', 'total_pages': 107, 'page': 36, 'page_label': '37', 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "# below we embed query first and then fetch results with similarity scores\n",
    "query_embedded = embedding.embed_query(\"How were Nike's margins impacted in 2023?\")\n",
    "\n",
    "results = vector_store.similarity_search_with_score_by_vector(query_embedded)\n",
    "doc, score = results[0]\n",
    "print(f\"Score: {score}\\n\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RETRIEVERS\n",
    "They are `runnables` that take a query, fetches & displays relevant texts as per query. We can either create a custom `retriver` or use the same using `vector store`. \n",
    "\n",
    "Below shows an implementation using `vector store`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create retriever from vector store\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type = \"similarity\",\n",
    "    search_kwargs = {'k':1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass queries to retriever & fetch results\n",
    "result = retriever.batch(\n",
    "    [\n",
    "        \"How many distribution centers does Nike have in the US?\",\n",
    "        \"When was Nike incorporated?\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Table of Contents\\nPART I\\nITEM 1. BUSINESS\\nGENERAL\\nNIKE, Inc. was incorporated in 1967 under the laws of the State of Oregon. As used in this Annual Report on Form 10-K (this \"Annual Report\"), the terms \"we,\" \"us,\" \"our,\"\\n\"NIKE\" and the \"Company\" refer to NIKE, Inc. and its predecessors, subsidiaries and affiliates, collectively, unless the context indicates otherwise.\\nOur principal business activity is the design, development and worldwide marketing and selling of athletic footwear, apparel, equipment, accessories and services. NIKE is\\nthe largest seller of athletic footwear and apparel in the world. We sell our products through NIKE Direct operations, which are comprised of both NIKE-owned retail stores\\nand sales through our digital platforms (also referred to as \"NIKE Brand Digital\"), to retail accounts and to a mix of independent distributors, licensees and sales'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1][0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL AGENT\n",
    "Here we create an *SQL Agent* that considers user query converts to a database specific query and pass it to the backend database which in this case is a retail industry database named `Atliq T-shirt` in *MySQL* to extract necessary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLDatabase is a wrapper that provides a simple interface to run sql queries\n",
    "from langchain_community.utilities import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch necessary DB credentials\n",
    "load_dotenv('.env')\n",
    "user = os.getenv('DB_USER')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "localhost = os.getenv('DB_HOST')\n",
    "port = os.getenv('DB_PORT')\n",
    "\n",
    "db_name = 'atliq_tshirts'\n",
    "\n",
    "# create DB URI with above credentials\n",
    "db_uri = f'mysql+mysqlconnector://{user}:{password}@{localhost}:{port}/{db_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup connection to MYSQL database Atliq_tshirt using above URI\n",
    "db = SQLDatabase.from_uri(db_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FETCH DATABSE RELATED INFORMATION\n",
    "With connection established we can now fetch database related information such as, \n",
    "1. Tables \n",
    "2. Columns present \n",
    "3. Database engine etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database engine used is: mysql\n",
      "\n",
      "Available tables are: ['discounts', 't_shirts']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Database engine used is: {db.dialect}\\n')\n",
    "print(f'Available tables are: {db.get_usable_table_names()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOOLS FOR DATABASE INTERACTION\n",
    "Next we setup `tools` that help us interact with the database to do the following, \n",
    "1. Fetch list of tables present. \n",
    "2. Check on query written to be executed to pull information from database. \n",
    "3. fetch data from the database using query etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup toolkit for db interaction\n",
    "mysql_toolkit = SQLDatabaseToolkit(db=db,llm=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_db_query: Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\n",
      "\n",
      "sql_db_schema: Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3\n",
      "\n",
      "sql_db_list_tables: Input is an empty string, output is a comma-separated list of tables in the database.\n",
      "\n",
      "sql_db_query_checker: Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the different tools present with a corresponding short description of it.\n",
    "tools = mysql_toolkit.get_tools()\n",
    "\n",
    "for tool in tools:\n",
    "    print(f\"{tool.name}: {tool.description}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CREATE A DETAILED SYSTEM PROMPT\n",
    "We aim to setup the *SQL Agent* to behave like an analyst hence we provide it such a descriptive prompt. \n",
    "\n",
    "Notice the line `Never query for all columns under a table but only related ones` which says it pick and perform aggregation only on the columns that matter related to the user query. Also LLM's operate on a fixed token limit, by chosing to display all columns the token limit could overpass thereby crashing operation.\n",
    "\n",
    "Also since the LLM comes up with it's own query prior to executing it to fetch results from the database it might be that the query turns up incorrect. This makes it important to double-check the query and re-write it if necessary before execution, hence the prompt `ouble check your query before executing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a detailed system prompt to customise agent behaviour.\n",
    "system_prompt = \"\"\"\n",
    "You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct {dialect} query to run,\n",
    "then look at the results of the query and return the answer. Unless the user\n",
    "specifies a specific number of examples they wish to obtain, always limit your\n",
    "query to at most {top_k} results.\n",
    "\n",
    "You can order the results by a relevant column to return the most interesting\n",
    "examples in the database. Never query for all the columns from a specific table,\n",
    "only ask for the relevant columns given the question.\n",
    "\n",
    "You MUST double check your query before executing it. If you get an error while\n",
    "executing a query, rewrite the query and try again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
    "database.\n",
    "\n",
    "To start you should ALWAYS look at the tables in the database to see what you\n",
    "can query. DO NOT skip this step.\n",
    "\n",
    "NEVER expose internal identifiers such as IDs, primary keys, or surrogate keys. ALWAYS return human-readable attributes instead.\n",
    "\n",
    "NEVER show texts wrapped with ** around. ALWAYS display clean texts in response.\n",
    "\n",
    "NOTE that the price column in t_shirts table has the unit of Rs.\n",
    "\n",
    "Then you should query the schema of the most relevant tables.\n",
    "\"\"\".format(\n",
    "    dialect=db.dialect,\n",
    "    top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SETUP AND RUN THE AGENT\n",
    "Next we execute the agent with queries to see how well it answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many t-shirts do we have for Nike in extra-small and white color?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(BaseModel):\n",
    "    answer : str = Field(description='Final answer to user query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup agent\n",
    "sql_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    "    response_format=ProviderStrategy(Output)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer='We have 12 Nike t-shirts in extra-small (XS) and white color.'\n"
     ]
    }
   ],
   "source": [
    "response = sql_agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":query}]})\n",
    "print(response['structured_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many is the price of inventory for all small sized t-shirts?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer='The total price of inventory for all small (S) sized t-shirts is Rs 16,437.'\n"
     ]
    }
   ],
   "source": [
    "response = sql_agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":query}]})\n",
    "print(response['structured_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "If we sell all the Levi's t-shirts today with discounts applied how much revenue would that generate?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (call_j4bXatay6K6H5VyPWxY28vQc)\n",
      " Call ID: call_j4bXatay6K6H5VyPWxY28vQc\n",
      "  Args:\n",
      "    tool_input:\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "discounts, t_shirts\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_NFhS7bSwVWtEz3AyUhTsQ3I2)\n",
      " Call ID: call_NFhS7bSwVWtEz3AyUhTsQ3I2\n",
      "  Args:\n",
      "    table_names: t_shirts, discounts\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE discounts (\n",
      "\tdiscount_id INTEGER NOT NULL AUTO_INCREMENT, \n",
      "\tt_shirt_id INTEGER NOT NULL, \n",
      "\tpct_discount DECIMAL(5, 2), \n",
      "\tPRIMARY KEY (discount_id), \n",
      "\tCONSTRAINT discounts_ibfk_1 FOREIGN KEY(t_shirt_id) REFERENCES t_shirts (t_shirt_id), \n",
      "\tCONSTRAINT discounts_chk_1 CHECK ((`pct_discount` between 0 and 100))\n",
      ")COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\n",
      "\n",
      "/*\n",
      "3 rows from discounts table:\n",
      "discount_id\tt_shirt_id\tpct_discount\n",
      "1\t1\t10.00\n",
      "2\t2\t15.00\n",
      "3\t3\t20.00\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE t_shirts (\n",
      "\tt_shirt_id INTEGER NOT NULL AUTO_INCREMENT, \n",
      "\tbrand ENUM('Van Huesen','Levi','Nike','Adidas') NOT NULL, \n",
      "\tcolor ENUM('Red','Blue','Black','White') NOT NULL, \n",
      "\tsize ENUM('XS','S','M','L','XL') NOT NULL, \n",
      "\tprice INTEGER, \n",
      "\tstock_quantity INTEGER NOT NULL, \n",
      "\tPRIMARY KEY (t_shirt_id), \n",
      "\tCONSTRAINT t_shirts_chk_1 CHECK ((`price` between 10 and 50))\n",
      ")COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\n",
      "\n",
      "/*\n",
      "3 rows from t_shirts table:\n",
      "t_shirt_id\tbrand\tcolor\tsize\tprice\tstock_quantity\n",
      "1\tVan Huesen\tRed\tM\t32\t11\n",
      "2\tLevi\tRed\tXL\t31\t90\n",
      "3\tAdidas\tBlack\tXS\t34\t98\n",
      "*/\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query_checker (call_wxr4tOF7v194cFzYkewLCjl0)\n",
      " Call ID: call_wxr4tOF7v194cFzYkewLCjl0\n",
      "  Args:\n",
      "    query: SELECT \n",
      "  SUM(ts.stock_quantity * ts.price * (1 - COALESCE(d.pct_discount,0)/100)) AS revenue_rs\n",
      "FROM t_shirts ts\n",
      "LEFT JOIN discounts d ON d.t_shirt_id = ts.t_shirt_id\n",
      "WHERE ts.brand = 'Levi';\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: sql_db_query_checker\n",
      "\n",
      "SELECT \n",
      "  SUM(ts.stock_quantity * ts.price * (1 - COALESCE(d.pct_discount,0)/100)) AS revenue_rs\n",
      "FROM t_shirts ts\n",
      "LEFT JOIN discounts d ON d.t_shirt_id = ts.t_shirt_id\n",
      "WHERE ts.brand = 'Levi';\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query (call_W7s9BNrhAn87Jovbkkxd0pym)\n",
      " Call ID: call_W7s9BNrhAn87Jovbkkxd0pym\n",
      "  Args:\n",
      "    query: SELECT \n",
      "  SUM(ts.stock_quantity * ts.price * (1 - COALESCE(d.pct_discount,0)/100)) AS revenue_rs\n",
      "FROM t_shirts ts\n",
      "LEFT JOIN discounts d ON d.t_shirt_id = ts.t_shirt_id\n",
      "WHERE ts.brand = 'Levi';\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: sql_db_query\n",
      "\n",
      "[(Decimal('26289.500000'),)]\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "{\"answer\":\"Selling all Levi t-shirts today with the applicable discounts would generate Rs 26,289.50 in revenue.\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"If we sell all the Levi's t-shirts today with discounts applied how much revenue would that generate?\"\n",
    "\n",
    "for event in sql_agent.stream({\"messages\":[{\"role\":\"user\",\"content\":query}]},stream_mode=\"values\"):\n",
    "    last_message = event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer='We have 230 white color Levi’s t-shirts available in stock.'\n"
     ]
    }
   ],
   "source": [
    "query = \"How many white color Levi's t shirts do we have available?\"\n",
    "\n",
    "response = sql_agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":query}]})\n",
    "print(response['structured_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FEW-SHOT EXAMPLES\n",
    "`FEW SHOT EXAMPLES` are a way to improve LLM performance by coming up with the right set of SQL queries everytime a user asks a question. \n",
    "\n",
    "Usually `FEW SHOT EXMAPLES` are included in the system prompt in the form, \n",
    "\n",
    "User: Question\n",
    "SQL : sql query that answers the question. \n",
    "\n",
    "**A good system prompt would be,**\n",
    "\n",
    "You are a SQL agent for a retail apparel database.\n",
    "\n",
    "Follow these rules:\n",
    "- Never use SELECT *\n",
    "- Only select columns required to answer the question\n",
    "- Use LEFT JOIN when optional data (e.g., discounts) may be missing\n",
    "- Do not expose internal IDs in the final answer\n",
    "- Prefer aggregation in SQL, not post-processing\n",
    "\n",
    "Examples:\n",
    "\n",
    "User: What is the total revenue for Levi brand? \n",
    "\n",
    "SQL:\n",
    "SELECT\n",
    "  SUM(ts.stock_quantity * ts.price * (1 - COALESCE(d.pct_discount, 0)/100)) AS revenue\n",
    "FROM t_shirts ts\n",
    "LEFT JOIN discounts d ON d.t_shirt_id = ts.t_shirt_id\n",
    "WHERE ts.brand = 'Levi';\n",
    "\n",
    "User: Which T-shirt has the lowest discount? \n",
    "\n",
    "SQL:\n",
    "SELECT\n",
    "  ts.brand,\n",
    "  ts.color,\n",
    "  ts.size,\n",
    "  d.pct_discount\n",
    "FROM t_shirts ts\n",
    "JOIN discounts d ON d.t_shirt_id = ts.t_shirt_id\n",
    "ORDER BY d.pct_discount ASC\n",
    "LIMIT 1;\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
